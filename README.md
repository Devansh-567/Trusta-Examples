# ğŸ›¡ï¸ Trustra â€” Trust-First AutoML Framework

> **"One `fit()`. Full trust."**

Trustra is a **next-generation, open-source AutoML framework** that doesn't just maximize accuracy â€” it **ensures model integrity** by automatically detecting **data leakage, bias, drift, and instability** â€” and generating **auditable trust reports**.

Unlike traditional AutoML tools, **Trustra enforces responsibility by design**.

## ğŸš€ Why Trustra?

Most AutoML tools focus on *"How accurate is the model?"*  
Trustra asks:  
> â“ **"Can we trust this model?"**  
> â“ **"Is it fair?"**  
> â“ **"Is it safe for production?"**

We built Trustra because:
- Real-world models fail due to **hidden data issues**, not poor algorithms
- Bias goes undetected until it harms users
- Drift creeps in silently
- Teams waste weeks on manual validation

ğŸ‘‰ **Trustra automates trust.**

## âœ¨ Key Features

| Feature | Description |
|-------|-------------|
| ğŸ” **Data Quality Checks** | Detects missing values, duplicates, class imbalance, and **data leakage** |
| âš–ï¸ **Fairness Audit** | Automatically audits bias across sensitive features using **Demographic Parity & Equalized Odds** |
| ğŸ“‰ **Drift Detection** | Flags feature drift between train/validation using KS test |
| ğŸ§  **Auto Model Selection** | Uses **Optuna** to find the best model and hyperparameters |
| ğŸ“Š **Trust Report** | Generates a **self-contained HTML report** with model performance and detected issues |
| ğŸš€ **Simple API** | Just `model.fit(X_train, y_train)` â€” no complex pipelines |

## ğŸ† Results on Benchmark Data

| Metric | Result |
|-------|--------|
| **CV AUC** | 0.995 |
| **Bias (DPD)** | 0.051 (Low) |
| **Data Issues Found** | 0 |
| **Training Time** | < 10 seconds |

## ğŸš€ Quick Start

```bash
# Install from PyPI
pip install trustra

# Use in your Python script
from trustra import TrustRA

model = TrustRA(target="target_column", sensitive_features=["gender"])
model.fit(X_train, y_train, X_val, y_val)
```
- Generates: trustra_report.html â€” fully interactive, offline-ready.
---

## ğŸ“š Motivation
AI is powerful â€” but untrusted AI is dangerous.
From biased hiring models to faulty credit scoring, bad models cause real harm.

Trustra was built to:
- Democratize responsible AI
- Automate model validation
- Empower data scientists, auditors, and compliance teams
- Make trust the default, not an afterthought
---

## ğŸ›  Tech Stack
- Python 3.9+
- Optuna â€“ Hyperparameter tuning
- Scikit-learn â€“ Model training
- Plotly â€“ Interactive visualizations
- Fairlearn â€“ Fairness metrics
- Jinja2 â€“ HTML report templating
---

## ğŸ“„ License
MIT License
Copyright Â© 2025 Devansh Singh
---

## ğŸ‘¤ Author
> Devansh Singh
> devansh.jay.singh@gmail.com
> "Built Trustra to make AI trustworthy, one model at a time. "
